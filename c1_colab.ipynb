{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: AI大模型之美\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "8.209.200.186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 验证环境\n",
    "\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "print(sys.version)\n",
    "response = requests.get('http://eth0.me')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备环境\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"sk-...\"\n",
    "# EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test!\n"
     ]
    }
   ],
   "source": [
    "# 验证环境\n",
    "import openai\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test!\"}],\n",
    "    temperature=0.7,\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Factory Stock PVC Inflatable Frog Night Market Best-selling Inflatable Toy with Light for Children Water Play\",\n",
      "  \"selling_points\": [\n",
      "    \"High-quality PVC material\",\n",
      "    \"Inflatable and easy to carry\",\n",
      "    \"Glowing light for added fun\",\n",
      "    \"Perfect for water play\",\n",
      "    \"Ideal for night markets and outdoor events\"\n",
      "  ],\n",
      "  \"price_range\": \"$10 - $20\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Factory Stock PVC Inflatable Frog Night Market Best-selling Inflatable Toy with Light for Children Water Play\",\\n  \"selling_points\": [\\n    \"High-quality PVC material\",\\n    \"Inflatable and easy to carry\",\\n    \"Glowing light for added fun\",\\n    \"Perfect for water play\",\\n    \"Ideal for night markets and outdoor events\"\\n  ],\\n  \"price_range\": \"$10 - $20\"\\n}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 单轮对话\n",
    "\n",
    "content = \"\"\"\n",
    "Consideration product : 工厂现货PVC充气青蛙夜市地摊热卖充气玩具发光蛙儿童水上玩具\n",
    "\n",
    "1. Compose human readable product title used on Amazon in english within 20 words.\n",
    "2. Write 5 selling points for the products in Amazon.\n",
    "3. Evaluate a price range for this product in U.S.\n",
    "\n",
    "Output the result in json format with three properties called title, selling_points and price_range\n",
    "\"\"\"\n",
    "\n",
    "def one_round_dialog(content: str, max_tokens: int = 256) -> str:\n",
    "  response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": content}],\n",
    "    temperature=0.7,\n",
    "    max_tokens=max_tokens\n",
    "    )\n",
    "  message = response['choices'][0]['message']['content']\n",
    "  print(message)\n",
    "  return message\n",
    "\n",
    "one_round_dialog(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Ten Hag\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Ten Hag\"}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 机器翻译、文本生成、知识推理、命名实体识别\n",
    "\n",
    "content = \"\"\"\n",
    "Man Utd must win trophies, says Ten Hag ahead of League Cup final\n",
    "请将上面这句话的人名提取出来，并用json的方式展示出来\n",
    "\"\"\"\n",
    "\n",
    "one_round_dialog(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding（略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 你是谁？\n",
      "Assistant : 我是一个中国厨师，很高兴为您解答做菜的问题。请问有什么可以帮到您的呢？\n",
      "\n",
      "[{'role': 'system', 'content': '你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\\n1. 你的回答必须是中文\\n2. 回答限制在100个字以内'}, {'role': 'user', 'content': '你是谁？'}, {'role': 'assistant', 'content': '我是一个中国厨师，很高兴为您解答做菜的问题。请问有什么可以帮到您的呢？'}]\n",
      "User : 请问鱼香肉丝怎么做？\n",
      "Assistant : 鱼香肉丝的做法如下：1.将猪肉切成丝，用料酒、盐、淀粉腌制10分钟。2.将泡发好的木耳、胡萝卜、青椒切丝备用。3.热锅凉油，放入蒜末、姜末炒香。4.加入肉丝翻炒至变色，加入木耳、胡萝卜、青椒继续翻炒。5.加入酱油、糖、醋、盐、水混合的鱼香汁，翻炒均匀。6.最后加入适量的水淀粉勾芡，翻炒均匀即可。希望对您有帮助！\n",
      "\n",
      "[{'role': 'system', 'content': '你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\\n1. 你的回答必须是中文\\n2. 回答限制在100个字以内'}, {'role': 'user', 'content': '你是谁？'}, {'role': 'assistant', 'content': '我是一个中国厨师，很高兴为您解答做菜的问题。请问有什么可以帮到您的呢？'}, {'role': 'user', 'content': '请问鱼香肉丝怎么做？'}, {'role': 'assistant', 'content': '鱼香肉丝的做法如下：1.将猪肉切成丝，用料酒、盐、淀粉腌制10分钟。2.将泡发好的木耳、胡萝卜、青椒切丝备用。3.热锅凉油，放入蒜末、姜末炒香。4.加入肉丝翻炒至变色，加入木耳、胡萝卜、青椒继续翻炒。5.加入酱油、糖、醋、盐、水混合的鱼香汁，翻炒均匀。6.最后加入适量的水淀粉勾芡，翻炒均匀即可。希望对您有帮助！'}]\n",
      "User : 那蚝油牛肉呢？\n",
      "Assistant : 蚝油牛肉的做法如下：1. 将牛肉切成薄片，用料酒、盐、生粉腌制10分钟。2. 热锅凉油，放入蒜末、姜末炒香。3. 加入牛肉煸炒至变色，加入洋葱丝、青椒丝继续翻炒。4. 加入蚝油、酱油、糖、盐、水混合的调味汁，翻炒均匀。5. 最后加入适量的水淀粉勾芡，翻炒均匀即可。希望对您有帮助！\n",
      "\n",
      "[{'role': 'system', 'content': '你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\\n1. 你的回答必须是中文\\n2. 回答限制在100个字以内'}, {'role': 'user', 'content': '你是谁？'}, {'role': 'assistant', 'content': '我是一个中国厨师，很高兴为您解答做菜的问题。请问有什么可以帮到您的呢？'}, {'role': 'user', 'content': '请问鱼香肉丝怎么做？'}, {'role': 'assistant', 'content': '鱼香肉丝的做法如下：1.将猪肉切成丝，用料酒、盐、淀粉腌制10分钟。2.将泡发好的木耳、胡萝卜、青椒切丝备用。3.热锅凉油，放入蒜末、姜末炒香。4.加入肉丝翻炒至变色，加入木耳、胡萝卜、青椒继续翻炒。5.加入酱油、糖、醋、盐、水混合的鱼香汁，翻炒均匀。6.最后加入适量的水淀粉勾芡，翻炒均匀即可。希望对您有帮助！'}, {'role': 'user', 'content': '那蚝油牛肉呢？'}, {'role': 'assistant', 'content': '蚝油牛肉的做法如下：1. 将牛肉切成薄片，用料酒、盐、生粉腌制10分钟。2. 热锅凉油，放入蒜末、姜末炒香。3. 加入牛肉煸炒至变色，加入洋葱丝、青椒丝继续翻炒。4. 加入蚝油、酱油、糖、盐、水混合的调味汁，翻炒均匀。5. 最后加入适量的水淀粉勾芡，翻炒均匀即可。希望对您有帮助！'}]\n"
     ]
    }
   ],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, prompt, num_of_round):\n",
    "        self.prompt = prompt\n",
    "        self.num_of_round = num_of_round\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": self.prompt})\n",
    "\n",
    "    def ask(self, question):\n",
    "        try:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": question})\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=self.messages,\n",
    "                temperature=0.5,\n",
    "                max_tokens=2048,\n",
    "                top_p=1,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "\n",
    "        message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "\n",
    "        # 保留最近最近 num_of_round 轮对话\n",
    "        if len(self.messages) > self.num_of_round*2 + 1:\n",
    "            del self.messages[1:3]\n",
    "        return message\n",
    "\n",
    "prompt = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\"\"\"\n",
    "\n",
    "conv1 = Conversation(prompt, 3)\n",
    "question1 = \"你是谁？\"\n",
    "print(f\"User : {question1}\")\n",
    "print(f\"Assistant : {conv1.ask(question1)}\\n\")\n",
    "print(conv1.messages)\n",
    "\n",
    "question2 = \"请问鱼香肉丝怎么做？\"\n",
    "print(f\"User : {question2}\")\n",
    "print(f\"Assistant : {conv1.ask(question2)}\\n\")\n",
    "print(conv1.messages)\n",
    "\n",
    "question3 = \"那蚝油牛肉呢？\"\n",
    "print(f\"User : {question3}\")\n",
    "print(f\"Assistant : {conv1.ask(question3)}\\n\")\n",
    "print(conv1.messages)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User : 我问你的第一个问题是什么？\n",
      "Assistant : 您的第一个问题是\"请问鱼香肉丝怎么做？\"。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question4 = \"我问你的第一个问题是什么？\"\n",
    "print(f\"User : {question4}\")\n",
    "print(f\"Assistant : {conv1.ask(question4)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")  # 下载encoding，只需要运行一次\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")  # 根据模型加载合适的encoding\n",
    "\n",
    "len(encoding.encode(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3132/3777087875.py:21: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "prompt = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\"\"\"\n",
    "\n",
    "conv = Conversation(prompt, 3)\n",
    "\n",
    "def answer(question, history=[]):\n",
    "    history.append(question)\n",
    "    response = conv.ask(question)\n",
    "    history.append(response)\n",
    "    responses = [(u,b) for u,b in zip(history[::2], history[1::2])]\n",
    "    return responses, history\n",
    "\n",
    "with gr.Blocks(css=\"#chatbot{height:300px} .overflow-y-auto{height:500px}\") as demo:\n",
    "    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n",
    "    state = gr.State([])\n",
    "\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\").style(container=False)\n",
    "\n",
    "    txt.submit(answer, [txt, state], [chatbot, state])\n",
    "\n",
    "demo.launch(server_name='0.0.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS（略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'orange']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "system_template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'北京和上海是中国最著名和最大的城市之一，它们有许多不同之处。\\n\\n1. 历史和文化：北京是中国的首都，有着悠久的历史和文化遗产，如故宫、长城等。上海则是中国的经济中心和文化中心，有着现代化的建筑和历史文化遗址，如外滩、城隍庙等。\\n\\n2. 地理环境：北京位于中国的北部，是一个平原城市，气候干燥，冬季寒冷。上海位于中国的东部，是一个沿海城市，气候温和，夏季炎热。\\n\\n3. 人口和经济发展：北京是中国的首都，人口众多，经济发展也非常迅速，是中国最重要的城市之一。上海则是中国的经济中心，人口较少，但经济发展也非常迅速，是中国最重要的城市之一。\\n\\n4. 交通和基础设施建设：北京和上海的交通都很方便，北京有地铁、公交、出租车等多种交通方式，而上海则有地铁、公交、出租车、地铁、高铁等多种交通方式。此外，北京和上海的基础设施建设也有所不同，如道路、桥梁、机场、港口等。\\n\\n北京和上海都是中国的重要城市，它们有许多不同之处，可以根据自己的兴趣和需求选择适合自己的城市进行旅游。'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import ChatGLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "template = \"\"\"{question}\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# default endpoint_url for a local deployed ChatGLM api server\n",
    "endpoint_url = \"http://127.0.0.1:8000\"\n",
    "\n",
    "# direct access endpoint in a proxied environment\n",
    "# os.environ['NO_PROXY'] = '127.0.0.1'\n",
    "\n",
    "llm = ChatGLM(\n",
    "    endpoint_url=endpoint_url,\n",
    "    max_token=80000,\n",
    "    history=[[\"我将从美国到中国来旅游，出行前希望了解中国的城市\", \"欢迎问我任何问题。\"]],\n",
    "    top_p=0.9,\n",
    "    model_kwargs={\"sample_model_args\": False},\n",
    ")\n",
    "\n",
    "# turn on with_history only when you want the LLM object to keep track of the conversation history\n",
    "# and send the accumulated context to the backend model api, which make it stateful. By default it is stateless.\n",
    "# llm.with_history = True\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"北京和上海两座城市有什么不同？\"\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这段文本描述了一些水果的价格，这些数据是按美元计算的。文本中使用了表格形式，列出了每种水果的颜色和价格。此外，文本还提到了这些水果的产地，例如苹果来自美国，草莓来自欧洲，橙子来自中国等等。'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"\"\"\n",
    "这段文本有什么特点？\n",
    "[Fruit, Color, Price (USD)] [Apple, Red, 1.20] [Banana, Yellow, 0.50] [Orange, Orange, 0.80] [Strawberry, Red, 2.50] [Blueberry, Blue, 3.00] [Kiwi, Green, 1.00] [Mango, Orange, 1.50] [Grape, Purple, 2.00]\n",
    "\"\"\"\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[水果， 颜色， 价格(美元)] [苹果， 红色， 1.20] [香蕉， 黄色， 0.50] [橙子， 橙色， 0.80] [草莓， 红色， 2.50] [蓝莓， 蓝色， 3.00] [猕猴桃， 绿色， 1.00] [芒果， 橙色， 1.50] [葡萄， 紫色， 2.00]'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"\"\"\n",
    "你是一个翻译专家。将以下所有的 English 翻译为 Chinese。\n",
    "特别注意，对于形如表格的文字，输出时不得使用全角逗号。\n",
    "\n",
    "例如：\n",
    "[Fruit, Color, Price (USD)] [Apple, Red, 1.20] [Banana, Yellow, 0.50] [Orange, Orange, 0.80] [Strawberry, Red, 2.50] [Blueberry, Blue, 3.00] [Kiwi, Green, 1.00] [Mango, Orange, 1.50] \n",
    "的翻译结果应该是：\n",
    "[水果, 颜色, 价格（美元）] [苹果, 红色, 1.20] [香蕉, 黄色, 0.50] [橙子, 橙色, 0.80] [草莓, 红色, 2.50] [蓝莓, 蓝色, 3.00] [猕猴桃, 绿色, 1.00] [芒果, 橙色, 1.50] \n",
    "\n",
    "文本如下：[Fruit, Color, Price (USD)] [Apple, Red, 1.20] [Banana, Yellow, 0.50] [Orange, Orange, 0.80] [Strawberry, Red, 2.50] [Blueberry, Blue, 3.00] [Kiwi, Green, 1.00] [Mango, Orange, 1.50] [Grape, Purple, 2.00]\n",
    "\"\"\"\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
